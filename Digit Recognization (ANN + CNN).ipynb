{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, I will train multilayer neural network in TensorFlow and Keras. I will use MNIST Hand written digit dataset. The goal is to build a model to recognize the hand written digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Required packages\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import imageio\n",
    "import pylab\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Process the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (49000, 28, 28)\n",
      "test: (21000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read Test / Train Images\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "\n",
    "#Read Images: Images are located in ./Images/train/*.png format\n",
    "\n",
    "def read_images(path_to_dir, dataset = train):\n",
    "    temp = []\n",
    "    for image in dataset.filename:\n",
    "        image_path = os.path.join(path_to_dir,image)\n",
    "        img = imageio.imread(image_path, as_gray=True)\n",
    "        img = img.astype('float32')\n",
    "        temp.append(img)\n",
    "    return np.stack(temp)\n",
    "    \n",
    "X_train = read_images(\"./Images/train/\", train)\n",
    "X_test = read_images(\"./Images/test/\", test)\n",
    "\n",
    "Y_train = np.array(train.label.tolist())\n",
    "\n",
    "print \"train:\", X_train.shape\n",
    "print \"test:\", X_test.shape\n",
    "\n",
    "plt.imshow(X_train[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, load Keras MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "\n",
    "# normalize x\n",
    "X_train = X_train.astype(float) / 255.\n",
    "X_test = X_test.astype(float) / 255.\n",
    "\n",
    "# reserve the last 10000 training examples for validation\n",
    "X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 50000 images. Each with the dim of 28 X 28\n",
      "Test: 10000 images. Each with the dim of 28 X 28\n"
     ]
    }
   ],
   "source": [
    "print \"Train:\", X_train.shape[0], \"images. Each with the dim of\", X_train.shape[1], \"X\", X_train.shape[2]\n",
    "print \"Test:\", X_test.shape[0], \"images. Each with the dim of\", X_test.shape[1], \"X\", X_test.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1.  This means that there are 50,000 training images. Each with the dimension of 28 X 28 pixels. We need to flatten this so that each training image is one row and number of columns\n",
    "are 728 (= 28 x 28). This will make 728 input features for our model***\n",
    "\n",
    "***2.  The output is a vector containig the true digit with values in [0,1,2,3,4,5,6,7,8,9] (10 classes). For modeling purpose, we need hot encode the output.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening: (50000, 28, 28)\n",
      "After flattening: (50000, 784)\n",
      "Before Hot Encoding: (50000,)\n",
      "After Hot Encoding: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training, validate and test examples + Hot encode Y labels\n",
    "\n",
    "def preprocess(X,y):\n",
    "    X_out = np.reshape(X,(X.shape[0],X.shape[1]*X.shape[2]))\n",
    "    n_values = np.max(y) + 1\n",
    "    y_hot = np.eye(n_values)[y]\n",
    "    return X_out, y_hot\n",
    "\n",
    "X_train_flatten, y_train_one_hot = preprocess(X_train, y_train)\n",
    "X_val_flatten, y_val_one_hot = preprocess(X_val, y_val)\n",
    "X_test_flatten, y_test_one_hot = preprocess(X_test, y_test)\n",
    "\n",
    "print \"Before flattening:\", X_train.shape\n",
    "print \"After flattening:\", X_train_flatten.shape\n",
    "\n",
    "print \"Before Hot Encoding:\", y_train.shape\n",
    "print \"After Hot Encoding:\",y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creator(batch_size, x_train, y_train):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    \n",
    "    batch_mask = rng.choice(x_train.shape[0], batch_size)\n",
    "    batch_x = x_train[batch_mask]\n",
    "    batch_y = y_train[batch_mask]   \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression Model:\n",
    "\n",
    "*** Model: W.X + b ***\n",
    "\n",
    "- X = [50000, 784]\n",
    "- W = [784, 10] \n",
    "- b = [50000,10]\n",
    "- Y = [50000,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "total_batch = int(X_train_flatten.shape[0]/batch_size)\n",
    "\n",
    "\n",
    "# creating placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, X_train_flatten.shape[1]])\n",
    "y = tf.placeholder(tf.float32, shape=[None, y_train_one_hot.shape[1]])\n",
    "\n",
    "# creating variables\n",
    "W = tf.Variable(tf.zeros([X_train_flatten.shape[1], y_train_one_hot.shape[1]]))\n",
    "b = tf.Variable(tf.zeros(y_train_one_hot.shape[1]))\n",
    "     \n",
    "# initializing the model\n",
    "y_pred = tf.matmul(x,W) + b\n",
    " \n",
    "# Defining Cost Function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = y_pred, labels = y))\n",
    "  \n",
    "# Implementing Gradient Descent Algorithm\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 cost = 1.62157\n",
      "Epoch: 10 cost = 0.37400\n",
      "Epoch: 20 cost = 0.31316\n",
      "Epoch: 30 cost = 0.29382\n",
      "Epoch: 40 cost = 0.28256\n",
      "Epoch: 50 cost = 0.27833\n",
      "Epoch: 60 cost = 0.27030\n",
      "Epoch: 70 cost = 0.27045\n",
      "Epoch: 80 cost = 0.26334\n",
      "Epoch: 90 cost = 0.25327\n",
      "\n",
      "Training complete!\n",
      "Validation Accuracy: 0.9314\n",
      "Test Accuracy: 0.9262\n"
     ]
    }
   ],
   "source": [
    "# Initializing the session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    " \n",
    "    # Creating batches of data for epochs\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0 \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = batch_creator(batch_size, X_train_flatten, y_train_one_hot)\n",
    "            _, c = sess.run([train_op, cross_entropy], feed_dict = {x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        if epoch%10 == 0:    \n",
    "            print \"Epoch:\", (epoch), \"cost =\", \"{:.5f}\".format(avg_cost)\n",
    "  \n",
    "\n",
    "    print \"\\nTraining complete!\"\n",
    "     \n",
    "    # Print Accuracy of the model\n",
    "    pred_temp = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "    print \"Validation Accuracy:\", accuracy.eval({x: X_val_flatten, y:y_val_one_hot})\n",
    "    print \"Test Accuracy:\", accuracy.eval({x: X_test_flatten, y:y_test_one_hot})\n",
    "    \n",
    "    predict = tf.argmax(y_pred, 1)\n",
    "    pred = predict.eval({x: X_test_flatten})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Model Outline (Computational Graph):***\n",
    "\n",
    "* Hidden Layer1 Z1 = W1*X + b1 ---> A1 = ReLu(Z1)\n",
    "* Hidden Layer2 Z2 = W2*A1 + b2 ---> A2 = ReLu(Z2)\n",
    "* Output Layter = W3*A2 + b3 \n",
    "\n",
    "\n",
    "*** Run the model: ***\n",
    "\n",
    "- for each epoch, do:\n",
    "- for each batch, do:\n",
    "- create pre-processed batch\n",
    "- run optimizer by feeding batch\n",
    "- find cost and reiterate to minimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in each layer\n",
    "input_num_units = 28*28\n",
    "hidden_num_units1 = 200\n",
    "hidden_num_units2 = 300\n",
    "output_num_units = 10\n",
    "epochs = 200\n",
    "batch_size = 512\n",
    "learning_rate = 0.02\n",
    "\n",
    "\n",
    "# define input placeholders\n",
    "x = tf.placeholder(tf.float32, [None, input_num_units])\n",
    "y = tf.placeholder(tf.float32, [None, output_num_units])\n",
    "\n",
    "\n",
    "# define weights and biases of the neural network\n",
    "weights = {\n",
    "    'hidden1': tf.Variable(tf.random_normal([input_num_units, hidden_num_units1], seed=seed)),\n",
    "    'hidden2': tf.Variable(tf.random_normal([hidden_num_units1, hidden_num_units2], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_num_units2, output_num_units], seed=seed))}\n",
    "\n",
    "biases = {\n",
    "    'hidden1': tf.Variable(tf.random_normal([hidden_num_units1], seed=seed)),\n",
    "    'hidden2': tf.Variable(tf.random_normal([hidden_num_units2], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))}\n",
    "\n",
    "# Define Layers\n",
    "hidden_layer1 = tf.add(tf.matmul(x, weights['hidden1']), biases['hidden1'])\n",
    "hidden_layer1 = tf.nn.relu(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = tf.add(tf.matmul(hidden_layer1, weights['hidden2']), biases['hidden2'])\n",
    "hidden_layer2 = tf.nn.relu(hidden_layer2)\n",
    "\n",
    "output_layer = tf.matmul(hidden_layer2, weights['output']) + biases['output']\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = output_layer, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 cost = 115.37379\n",
      "Epoch: 50 cost = 0.55731\n",
      "Epoch: 100 cost = 0.52511\n",
      "Epoch: 150 cost = 0.47539\n",
      "\n",
      "Training complete!\n",
      "Validation Accuracy: 0.9751\n",
      "Test Accuracy: 0.9759\n",
      "CPU times: user 8min 7s, sys: 42.5 s, total: 8min 49s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(X_train_flatten.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = batch_creator(batch_size, X_train_flatten, y_train_one_hot)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        if epoch%50 == 0:    \n",
    "            print \"Epoch:\", (epoch), \"cost =\", \"{:.5f}\".format(avg_cost)\n",
    "    \n",
    "    print \"\\nTraining complete!\"\n",
    "    \n",
    "    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "    print \"Validation Accuracy:\", accuracy.eval({x: X_val_flatten, y:y_val_one_hot})\n",
    "    print \"Test Accuracy:\", accuracy.eval({x: X_test_flatten, y:y_test_one_hot})\n",
    "    \n",
    "    predict = tf.argmax(output_layer, 1)\n",
    "    pred = predict.eval({x: X_test_flatten})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 220,310\n",
      "Trainable params: 220,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "\n",
    "model = Sequential(name=\"digit\")\n",
    "\n",
    "model.add(ll.InputLayer([28, 28]))\n",
    "\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "# network body\n",
    "model.add(ll.Dense(200))\n",
    "model.add(ll.Activation('relu'))\n",
    "\n",
    "model.add(ll.Dense(300))\n",
    "model.add(ll.Activation('relu'))\n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy but applied for one-hot-encoded vectors\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.4920 - acc: 0.8674 - val_loss: 0.1977 - val_acc: 0.9463\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1741 - acc: 0.9494 - val_loss: 0.1325 - val_acc: 0.9634\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1212 - acc: 0.9646 - val_loss: 0.1133 - val_acc: 0.9667\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0904 - acc: 0.9731 - val_loss: 0.0978 - val_acc: 0.9715\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0688 - acc: 0.9798 - val_loss: 0.0947 - val_acc: 0.9714\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0555 - acc: 0.9842 - val_loss: 0.0842 - val_acc: 0.9754\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0439 - acc: 0.9876 - val_loss: 0.0814 - val_acc: 0.9748\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0354 - acc: 0.9899 - val_loss: 0.0824 - val_acc: 0.9756\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0285 - acc: 0.9921 - val_loss: 0.0766 - val_acc: 0.9776\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0236 - acc: 0.9940 - val_loss: 0.0790 - val_acc: 0.9777\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0184 - acc: 0.9953 - val_loss: 0.0803 - val_acc: 0.9783\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0146 - acc: 0.9966 - val_loss: 0.0834 - val_acc: 0.9760\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0128 - acc: 0.9972 - val_loss: 0.0809 - val_acc: 0.9795\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0116 - acc: 0.9969 - val_loss: 0.0796 - val_acc: 0.9799\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0080 - acc: 0.9985 - val_loss: 0.0832 - val_acc: 0.9786\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0830 - val_acc: 0.9798\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0845 - val_acc: 0.9793\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0838 - val_acc: 0.9793\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0831 - val_acc: 0.9809\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0850 - val_acc: 0.9805\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0841 - val_acc: 0.9806\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9804\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 9.9006e-04 - acc: 1.0000 - val_loss: 0.0886 - val_acc: 0.9805\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9806\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 8.3466e-04 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 0.9809\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.8138e-04 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9813\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.9362e-04 - acc: 1.0000 - val_loss: 0.0902 - val_acc: 0.9811\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.3555e-04 - acc: 1.0000 - val_loss: 0.0902 - val_acc: 0.9817\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.7291e-04 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9808\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 4.3193e-04 - acc: 1.0000 - val_loss: 0.0937 - val_acc: 0.9807\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 4.0163e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9802\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 3.6605e-04 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9808\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.2132e-04 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9807\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.9360e-04 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9810\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.6860e-04 - acc: 1.0000 - val_loss: 0.0958 - val_acc: 0.9811\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.4767e-04 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9810\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2484e-04 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9815\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.0548e-04 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9808\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.8798e-04 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9807\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7301e-04 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9805\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5995e-04 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9812\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5159e-04 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9807\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3782e-04 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9810\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3073e-04 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 0.9808\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1806e-04 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9808\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.0962e-04 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9806\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.0085e-04 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9809\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 9.4715e-05 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9810\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 8.5131e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9809\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 7.9720e-05 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9807\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 7.5593e-05 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9803\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.9565e-05 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9806\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.4691e-05 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9803\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.9959e-05 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9805\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.6149e-05 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9812\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.2759e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9807\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.9013e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9809\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.5770e-05 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9808\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.3153e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9804\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.0432e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9804\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.7954e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9803\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.5020e-05 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9807\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.3099e-05 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9806\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.0658e-05 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9812\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.8573e-05 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9804\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.6572e-05 - acc: 1.0000 - val_loss: 0.1126 - val_acc: 0.9804\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.5416e-05 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9804\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.3753e-05 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9804\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2249e-05 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9806\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.0542e-05 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9802\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.9385e-05 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9808\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.8042e-05 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9806\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7205e-05 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9807\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.6015e-05 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9805\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4935e-05 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9807\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4252e-05 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9808\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3310e-05 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9804\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2654e-05 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9804\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1820e-05 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9806\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.0973e-05 - acc: 1.0000 - val_loss: 0.1200 - val_acc: 0.9804\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.0363e-05 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9807\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 9.8712e-06 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.9806\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 9.1860e-06 - acc: 1.0000 - val_loss: 0.1208 - val_acc: 0.9804\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 8.6619e-06 - acc: 1.0000 - val_loss: 0.1207 - val_acc: 0.9804\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 8.1127e-06 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9805\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 7.7332e-06 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9808\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 7.2573e-06 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9806\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.7880e-06 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9807\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.4478e-06 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9810\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.0535e-06 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 0.9805\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.6561e-06 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9804\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.3644e-06 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9801\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.1416e-06 - acc: 1.0000 - val_loss: 0.1248 - val_acc: 0.9809\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.7865e-06 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9804\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.5298e-06 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9804\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.2916e-06 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9807\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.0296e-06 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9802\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.7714e-06 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9801\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.5591e-06 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9802\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.3468e-06 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9805\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.2125e-06 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9805\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.0232e-06 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9809\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.8604e-06 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9804\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.6750e-06 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9804\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.5355e-06 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9805\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.4297e-06 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9805\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2606e-06 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9804\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.1586e-06 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9807\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.0525e-06 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9805\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.9153e-06 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9808\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.8360e-06 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9804\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7323e-06 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9805\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.6404e-06 - acc: 1.0000 - val_loss: 0.1333 - val_acc: 0.9802\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5549e-06 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9804\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4687e-06 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 0.9801\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4001e-06 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9803\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3229e-06 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9804\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2585e-06 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9805\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2004e-06 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9806\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1421e-06 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9806\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.0794e-06 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9804\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.0201e-06 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9804\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 9.7622e-07 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9804\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 9.3414e-07 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9808\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 8.8114e-07 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9804\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 8.5107e-07 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9804\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 7.9718e-07 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9804\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 7.6223e-07 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9806\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 7.2768e-07 - acc: 1.0000 - val_loss: 0.1392 - val_acc: 0.9806\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.9745e-07 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9805\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.6239e-07 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9805\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.4105e-07 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9807\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 6.1218e-07 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9806\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.7921e-07 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9808\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.5540e-07 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9807\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.2815e-07 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9805\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 5.0882e-07 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9806\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.8845e-07 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9807\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.6487e-07 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9803\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.5231e-07 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9808\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.3527e-07 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9806\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.1531e-07 - acc: 1.0000 - val_loss: 0.1432 - val_acc: 0.9806\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 4.0358e-07 - acc: 1.0000 - val_loss: 0.1436 - val_acc: 0.9803\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.8363e-07 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 0.9806\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.7029e-07 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9806\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.5632e-07 - acc: 1.0000 - val_loss: 0.1446 - val_acc: 0.9805\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.4428e-07 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9804\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.3209e-07 - acc: 1.0000 - val_loss: 0.1449 - val_acc: 0.9804\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.2222e-07 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9806\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.1011e-07 - acc: 1.0000 - val_loss: 0.1458 - val_acc: 0.9806\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 3.0290e-07 - acc: 1.0000 - val_loss: 0.1461 - val_acc: 0.9804\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.9028e-07 - acc: 1.0000 - val_loss: 0.1464 - val_acc: 0.9804\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.8274e-07 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9806\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.7448e-07 - acc: 1.0000 - val_loss: 0.1469 - val_acc: 0.9806\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.6674e-07 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9806\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.5667e-07 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 0.9806\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.5035e-07 - acc: 1.0000 - val_loss: 0.1482 - val_acc: 0.9807\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.4421e-07 - acc: 1.0000 - val_loss: 0.1483 - val_acc: 0.9806\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.3777e-07 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.9804\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.3084e-07 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.9808\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2531e-07 - acc: 1.0000 - val_loss: 0.1492 - val_acc: 0.9807\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2030e-07 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9806\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.1591e-07 - acc: 1.0000 - val_loss: 0.1497 - val_acc: 0.9807\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.0974e-07 - acc: 1.0000 - val_loss: 0.1500 - val_acc: 0.9807\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.0559e-07 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.9809\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.0098e-07 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9807\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.9693e-07 - acc: 1.0000 - val_loss: 0.1506 - val_acc: 0.9808\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.9244e-07 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9810\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.8991e-07 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9810\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.8576e-07 - acc: 1.0000 - val_loss: 0.1515 - val_acc: 0.9809\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.8220e-07 - acc: 1.0000 - val_loss: 0.1506 - val_acc: 0.9810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7911e-07 - acc: 1.0000 - val_loss: 0.1514 - val_acc: 0.9811\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7597e-07 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.9809\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7282e-07 - acc: 1.0000 - val_loss: 0.1523 - val_acc: 0.9807\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7099e-07 - acc: 1.0000 - val_loss: 0.1522 - val_acc: 0.9809\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.6801e-07 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.9809\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.6517e-07 - acc: 1.0000 - val_loss: 0.1526 - val_acc: 0.9809\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.6304e-07 - acc: 1.0000 - val_loss: 0.1530 - val_acc: 0.9808\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.6068e-07 - acc: 1.0000 - val_loss: 0.1533 - val_acc: 0.9810\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5872e-07 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9808\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5642e-07 - acc: 1.0000 - val_loss: 0.1539 - val_acc: 0.9810\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5452e-07 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.9806\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5303e-07 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.9806\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5122e-07 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.9807\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4955e-07 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.9810\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4779e-07 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.9810\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4648e-07 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.9806\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4520e-07 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.9810\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4392e-07 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9811\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4259e-07 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.9812\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4151e-07 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.9807\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4036e-07 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9808\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3919e-07 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9809\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3831e-07 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 0.9809\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3747e-07 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9810\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3632e-07 - acc: 1.0000 - val_loss: 0.1567 - val_acc: 0.9808\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3573e-07 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.9809\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3464e-07 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.9809\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3373e-07 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9809\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3321e-07 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.9809\n",
      "CPU times: user 11min 27s, sys: 1min 4s, total: 12min 32s\n",
      "Wall time: 2min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a40d5d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train_one_hot, validation_data=(X_val, y_val_one_hot), epochs=200, batch_size = 512);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/step\n",
      "('Loss, Accuracy = ', [0.17446766940470565, 0.9797])\n"
     ]
    }
   ],
   "source": [
    "# Save trained weights\n",
    "model.save(\"digit_keras_ann_weights.h5\")\n",
    "print(\"Loss, Accuracy = \", model.evaluate(X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network (CNN) Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 32)        2912      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1000)              801000    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 814,182\n",
      "Trainable params: 814,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (5, 5), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
      "  \n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_samples = 60000\n",
    "validation_samples = 10000\n",
    "epoch = 30\n",
    "\n",
    "# ** Model Begins **\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(10, 5, 5, activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.0653 - acc: 0.9778 - val_loss: 0.0213 - val_acc: 0.9930\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0173 - val_acc: 0.9942\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0111 - acc: 0.9962 - val_loss: 0.0096 - val_acc: 0.9972\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0084 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0084 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0079 - val_acc: 0.9978\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0067 - val_acc: 0.9979\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0124 - val_acc: 0.9962\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0074 - val_acc: 0.9978\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0072 - val_acc: 0.9980\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.fit(X_train.reshape(X_train.shape[0], 28, 28, 1), y_train_one_hot, validation_data=(X_val.reshape(X_val.shape[0],28, 28, 1), y_val_one_hot), epochs=10, batch_size = 512)\n",
    "model.save_weights('digit_keras_cnn_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** To Predict using the model above, we need to reshape the test example into (1, 28,28,1) shape ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 1\n",
      "\n",
      "Predicted Value: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 37\n",
    "\n",
    "print \"True Value:\", y_test[index]\n",
    "plt.imshow(X_test[index])\n",
    "\n",
    "print \"\\nPredicted Value:\", np.argmax(model.predict(X_test[index].reshape(1,28,28,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
